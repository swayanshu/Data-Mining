{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/adoku14/Eclat-Python-Implementation/blob/master/eclat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    return [[0, 1, 2, 3, 4, 5, 6, 7, 8], [8, 31, 32 ], [33, 32, 35 ], [3, 39, 48 ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It creates C1 .C1 is a candidate itemset of size one. In the Apriori algorithm, we create C1, and then we’ll scan the dataset to see if these one itemsets meet our minimum support requirements. The itemsets that do meet our minimum requirements become L1. L1 then gets combined to become C2 and C2 will get filtered to become L2.\n",
    "\n",
    "Frozensets are sets that are frozen, which means they’re immutable; you can’t change them. You need to use the type frozenset instead of set because you’ll later use these sets as the key in a dictionary.\n",
    "\n",
    "You can’t create a set of just one integer in Python. It needs to be a list (try it out). That’s why you create a list of single-item lists. Finally, you sort the list and then map every item in the list to frozenset() and return this list of frozensets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "                \n",
    "    C1.sort()\n",
    "    return list(map(frozenset, C1))#use frozen set so we\n",
    "                            #can use it as a key in a dict    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes three arguments: a dataset, Ck, a list of candidate sets, and minSupport, which is the minimum support you’re interested in. This is the function you’ll use to generate L1 from C1. Additionally, this function returns a dictionary with support values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanD(D, Ck, minSupport):\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                if not can in ssCnt: ssCnt[can]=1\n",
    "                else: ssCnt[can] += 1\n",
    "    numItems = float(len(D))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key]/numItems\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0,key)\n",
    "        supportData[key] = support\n",
    "    return retList, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8], [8, 31, 32], [33, 32, 35], [3, 39, 48]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = loadDataSet()\n",
    "dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({0}),\n",
       " frozenset({1}),\n",
       " frozenset({2}),\n",
       " frozenset({3}),\n",
       " frozenset({4}),\n",
       " frozenset({5}),\n",
       " frozenset({6}),\n",
       " frozenset({7}),\n",
       " frozenset({8}),\n",
       " frozenset({31}),\n",
       " frozenset({32}),\n",
       " frozenset({33}),\n",
       " frozenset({35}),\n",
       " frozenset({39}),\n",
       " frozenset({48})]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1 = createC1(dataSet)\n",
    "C1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C1 contains a list of all the items in frozenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 1, 2, 3, 4, 5, 6, 7, 8}, {8, 31, 32}, {32, 33, 35}, {3, 39, 48}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#D is a dataset in the setform.\n",
    "\n",
    "D = list(map(set,dataSet))\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have everything in set form, you can remove items that don’t meet our minimum support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({32}), frozenset({8}), frozenset({3})]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1,suppDat0 = scanD(D,C1,0.5)\n",
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These four items make up our L1 list, that is, the list of one-item sets that occur in at least 50% of all transactions. Item 4 didn’t make the minimum support level, so it’s not a part of L1. That’s OK. By removing it, you’ve removed more work from when you find the list of two-item sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori algorithm\n",
    "\n",
    "\n",
    "While the number of items in the set is greater than 0:\n",
    "\n",
    "Create a list of candidate itemsets of length k\n",
    "\n",
    "Scan the dataset to see if each itemset is frequent\n",
    "\n",
    "Keep frequent itemsets to create itemsets of length k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function is apriori(); it calls aprioriGen() to create candidate itemsets: Ck.\n",
    "\n",
    "The function aprioriGen() will take a list of frequent itemsets, Lk, and the size of the itemsets, k, to produce Ck. For example, it will take the itemsets {0}, {1}, {2} and so on and produce {0,1} {0,2}, and {1,2}.\n",
    "\n",
    "The sets are combined using the set union, which is the | symbol in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprioriGen(Lk, k): #creates Ck\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk): \n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort(); L2.sort()\n",
    "            if L1==L2: #if first k-2 elements are equal\n",
    "                retList.append(Lk[i] | Lk[j]) #set union\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(dataSet, minSupport = 0.5):\n",
    "    C1 = createC1(dataSet)\n",
    "    D = list(map(set, dataSet))\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):\n",
    "        Ck = aprioriGen(L[k-2], k)\n",
    "        Lk, supK = scanD(D, Ck, minSupport)#scan DB to get Lk\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[frozenset({32}), frozenset({8}), frozenset({3})], []]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L,suppData = apriori(dataSet)\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L contains some lists of frequent itemsets that met a minimum support of 0.5. The variable suppData is a dictionary with the support values of our itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({32}), frozenset({8}), frozenset({3})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({8, 32}), frozenset({3, 32}), frozenset({3, 8})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprioriGen(L[0],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining association rules from frequent item sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generateRules(), is the main command, which calls the other two.\n",
    "\n",
    "The generateRules() function takes three inputs: a list of frequent itemsets, a dictionary of support data for those itemsets, and a minimum confidence threshold. It’s going to generate a list of rules with confidence values that we can sort through later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRules(L, supportData, minConf=0.7):  #supportData is a dict coming from scanD\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):#only get the sets with two or more items\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if (i > 1):\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calcConf() calculates the confidence of the rule and then find out the which rules meet the minimum confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    prunedH = [] #create new list to return\n",
    "    for conseq in H:\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] #calc confidence\n",
    "        if conf >= minConf: \n",
    "            print (freqSet-conseq,'-->',conseq,'conf:',conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rulesFromConseq() generates more association rules from our initial dataset. This takes a frequent itemset and H, which is a list of items that could be on the right-hand side of a rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)): #try further merging\n",
    "        Hmp1 = aprioriGen(H, m+1)#create Hm+1 new candidates\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)\n",
    "        if (len(Hmp1) > 1):    #need at least two sets to merge\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "L,suppData= apriori(dataSet,minSupport=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules= generateRules(L,suppData, minConf=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives you three rules: {1} ➞ {3},{5} ➞ {2},and {2} ➞ {5}. It’s interesting to see that the rule with 2 and 5 can be flipped around but not the rule with 1 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatSet = [line.split() for line in open('retail.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "L,suppData= apriori(DatSet, minSupport=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in L[1]:\n",
    "    if item.intersection('2'):\n",
    "        print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in L[1]:\n",
    "    if item.intersection('2'):\n",
    "        print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules= generateRules(L,suppData, minConf=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables:\n",
    "#name of the node, a count\n",
    "#nodelink used to link similar items\n",
    "#parent vaiable used to refer to the parent of the node in the tree\n",
    "#node contains an empty dictionary for the children in the node\n",
    "class treeNode:\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur\n",
    "        self.nodeLink = None\n",
    "        self.parent = parentNode      #needs to be updated\n",
    "        self.children = {} \n",
    "#increments the count variable with a given amount    \n",
    "    def inc(self, numOccur):\n",
    "        self.count += numOccur\n",
    "#display tree in text. Useful for debugging        \n",
    "    def disp(self, ind=1):\n",
    "        print ('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootNode = treeNode('pyramid',9,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootNode.children['eye'] = treeNode('eye',13,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pyramid   9\n",
      "     eye   13\n"
     ]
    }
   ],
   "source": [
    "rootNode.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet, minSup=1): #create FP-tree from dataset but don't mine\n",
    "    headerTable = {}\n",
    "    #go over dataSet twice\n",
    "    for trans in dataSet:#first pass counts frequency of occurance\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    for k in list(headerTable):  #remove items not meeting minSup\n",
    "        if headerTable[k] < minSup: \n",
    "            del(headerTable[k])\n",
    "    freqItemSet = set(headerTable.keys())\n",
    "    #print 'freqItemSet: ',freqItemSet\n",
    "    if len(freqItemSet) == 0: return None, None  #if no items meet min support -->get out\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] #reformat headerTable to use Node link \n",
    "    #print 'headerTable: ',headerTable\n",
    "    retTree = treeNode('Null Set', 1, None) #create tree\n",
    "    for tranSet, count in dataSet.items():  #go through dataset 2nd time\n",
    "        localD = {}\n",
    "        for item in tranSet:  #put transaction items in order\n",
    "            if item in freqItemSet:\n",
    "                localD[item] = headerTable[item][0]\n",
    "        if len(localD) > 0:\n",
    "            orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)]\n",
    "            updateTree(orderedItems, retTree, headerTable, count)#populate tree with ordered freq itemset\n",
    "    return retTree, headerTable #return tree and header table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTree(items, inTree, headerTable, count):\n",
    "    if items[0] in inTree.children:#check if orderedItems[0] in retTree.children\n",
    "        inTree.children[items[0]].inc(count) #incrament count\n",
    "    else:   #add items[0] to inTree.children\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        if headerTable[items[0]][1] == None: #update header table \n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    if len(items) > 1:#call updateTree() with remaining ordered items\n",
    "        updateTree(items[1::], inTree.children[items[0]], headerTable, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateHeader(nodeToTest, targetNode):   #this version does not use recursion\n",
    "    while (nodeToTest.nodeLink != None):    #Do not use recursion to traverse a linked list!\n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSimpDat():\n",
    "    simpDat = [['r', 'z', 'h', 'j', 'p'],\n",
    "               ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'],\n",
    "               ['z'],\n",
    "               ['r', 'x', 'n', 'o', 's'],\n",
    "               ['y', 'r', 'x', 'z', 'q', 't', 'p'],\n",
    "               ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]\n",
    "    return simpDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInitSet(dataSet):\n",
    "    retDict = {}\n",
    "    for trans in dataSet:\n",
    "        retDict[frozenset(trans)] = 1\n",
    "    return retDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpDat = loadSimpDat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r', 'z', 'h', 'j', 'p'],\n",
       " ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'],\n",
       " ['z'],\n",
       " ['r', 'x', 'n', 'o', 's'],\n",
       " ['y', 'r', 'x', 'z', 'q', 't', 'p'],\n",
       " ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "initSet = createInitSet(simpDat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'h', 'j', 'p', 'r', 'z'}): 1,\n",
       " frozenset({'s', 't', 'u', 'v', 'w', 'x', 'y', 'z'}): 1,\n",
       " frozenset({'z'}): 1,\n",
       " frozenset({'n', 'o', 'r', 's', 'x'}): 1,\n",
       " frozenset({'p', 'q', 'r', 't', 'x', 'y', 'z'}): 1,\n",
       " frozenset({'e', 'm', 'q', 's', 't', 'x', 'y', 'z'}): 1}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The FP-tree\n",
    "myFPtree, myHeaderTab = createTree(initSet, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Null Set   1\n",
      "     z   5\n",
      "       r   1\n",
      "       x   3\n",
      "         t   2\n",
      "           s   2\n",
      "             y   2\n",
      "         r   1\n",
      "           t   1\n",
      "             y   1\n",
      "     x   1\n",
      "       r   1\n",
      "         s   1\n"
     ]
    }
   ],
   "source": [
    "myFPtree.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascendTree(leafNode, prefixPath): #ascends from leaf node to root\n",
    "    if leafNode.parent != None:\n",
    "        prefixPath.append(leafNode.name)\n",
    "        ascendTree(leafNode.parent, prefixPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPrefixPath(basePat, treeNode): #treeNode comes from header table\n",
    "    condPats = {}\n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        ascendTree(treeNode, prefixPath)\n",
    "        if len(prefixPath) > 1: \n",
    "            condPats[frozenset(prefixPath[1:])] = treeNode.count\n",
    "        treeNode = treeNode.nodeLink\n",
    "    return condPats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'z'}): 3}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findPrefixPath('x', myHeaderTab['x'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'z'}): 1, frozenset({'x'}): 1, frozenset({'x', 'z'}): 1}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findPrefixPath('r', myHeaderTab['r'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(r'D:\\2nd_semester\\data_mining\\assignment\\2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, itertools\n",
    "import pandas as pd\n",
    "np.random.seed(1)\n",
    "kot = 0\n",
    "FreqItems = dict()\n",
    "support = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "minsup = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eclat(prefix, items, dict_id):\n",
    "    while items:\n",
    "        i,itids = items.pop()\n",
    "        isupp = len(itids)\n",
    "        if isupp >= minsup:\n",
    "\n",
    "            FreqItems[frozenset(prefix + [i])] = isupp\n",
    "            suffix = []\n",
    "            for j, ojtids in items:\n",
    "                jtids = itids & ojtids\n",
    "                if len(jtids) >= minsup:\n",
    "                    suffix.append((j,jtids))\n",
    "\n",
    "            dict_id += 1\n",
    "            eclat(prefix+[i], sorted(suffix, key=lambda item: len(item[1]), reverse=True), dict_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Data(filename, delimiter=','):\n",
    "    data = {}\n",
    "    trans = 0\n",
    "    f = open(filename, 'r', encoding=\"utf8\")\n",
    "    for row in f:\n",
    "        trans += 1\n",
    "        for item in row.strip().split(delimiter):\n",
    "            if item not in data:\n",
    "                data[item] = set()\n",
    "            data[item].add(trans)\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " dict_id = 0\n",
    "eclat([], sorted(data.items(), key=lambda item: len(item[1]), reverse=True), dict_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Read_Data('retail-small.txt', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {1},\n",
       " '1': {1},\n",
       " '2': {1},\n",
       " '3': {1, 8},\n",
       " '4': {1},\n",
       " '5': {1},\n",
       " '6': {1},\n",
       " '7': {1},\n",
       " '8': {1},\n",
       " '9': {1},\n",
       " '10': {1},\n",
       " '11': {1},\n",
       " '12': {1},\n",
       " '13': {1},\n",
       " '14': {1},\n",
       " '15': {1},\n",
       " '16': {1},\n",
       " '17': {1},\n",
       " '18': {1},\n",
       " '19': {1},\n",
       " '20': {1},\n",
       " '21': {1},\n",
       " '22': {1},\n",
       " '23': {1},\n",
       " '24': {1},\n",
       " '25': {1},\n",
       " '26': {1},\n",
       " '27': {1},\n",
       " '28': {1},\n",
       " '29': {1},\n",
       " '30': {2},\n",
       " '31': {2},\n",
       " '32': {2, 7, 10},\n",
       " '33': {3},\n",
       " '34': {3},\n",
       " '35': {3},\n",
       " '36': {4, 13, 17},\n",
       " '37': {4},\n",
       " '38': {4, 5, 6, 13, 17},\n",
       " '39': {4, 5, 6, 8, 12, 13, 16, 17},\n",
       " '40': {4},\n",
       " '41': {4, 7, 13, 15},\n",
       " '42': {4},\n",
       " '43': {4},\n",
       " '44': {4},\n",
       " '45': {4},\n",
       " '46': {4},\n",
       " '47': {5},\n",
       " '48': {5, 6, 8, 11, 13, 16, 17},\n",
       " '49': {6},\n",
       " '50': {6},\n",
       " '51': {6},\n",
       " '52': {6},\n",
       " '53': {6},\n",
       " '54': {6},\n",
       " '55': {6},\n",
       " '56': {6},\n",
       " '57': {6},\n",
       " '58': {6},\n",
       " '59': {7},\n",
       " '60': {7},\n",
       " '61': {7},\n",
       " '62': {7},\n",
       " '63': {9},\n",
       " '64': {9},\n",
       " '65': {9},\n",
       " '66': {9},\n",
       " '67': {9},\n",
       " '68': {9},\n",
       " '69': {10},\n",
       " '70': {11},\n",
       " '71': {11},\n",
       " '72': {11},\n",
       " '73': {12},\n",
       " '74': {12},\n",
       " '75': {12},\n",
       " '76': {12},\n",
       " '77': {12},\n",
       " '78': {12},\n",
       " '79': {12, 13},\n",
       " '80': {13},\n",
       " '81': {13},\n",
       " '82': {14},\n",
       " '83': {14},\n",
       " '84': {14},\n",
       " '85': {15},\n",
       " '86': {15},\n",
       " '87': {15},\n",
       " '88': {15},\n",
       " '89': {16, 17},\n",
       " '90': {16},\n",
       " '91': {16},\n",
       " '92': {16},\n",
       " '93': {16},\n",
       " '94': {16},\n",
       " '95': {16},\n",
       " '96': {16},\n",
       " '97': {16},\n",
       " '98': {16},\n",
       " '99': {16},\n",
       " '100': {16},\n",
       " '101': {16}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rules(FreqItems, confidence):\n",
    "    Rules = []\n",
    "    cnt = 0\n",
    "\n",
    "    for items, support in FreqItems.items():\n",
    "        if (len(items) > 1):\n",
    "            all_perms = list(itertools.permutations(items, len(items)))\n",
    "            for lst in all_perms:\n",
    "                antecedent = lst[:len(lst) - 1]\n",
    "                consequent = lst[-1:]\n",
    "\n",
    "                conf = float(FreqItems[frozenset(items)]/FreqItems[frozenset(antecedent)]*100)\n",
    "                if (conf >= confidence):\n",
    "                    cnt += 1\n",
    "                    lift = float(conf/FreqItems[frozenset(consequent)])\n",
    "                    if lift >= 1:\n",
    "                        Rules.append((antecedent, consequent, support, conf, lift))\n",
    "\n",
    "\n",
    "    print('Found %d Rules ' % (cnt))\n",
    "    return Rules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getantecendent(FreqItems, confidence):\n",
    "    ant = []\n",
    "    cnt = 0\n",
    "\n",
    "    for items, support in FreqItems.items():\n",
    "        if(len(items) > 1):\n",
    "            all_perms = list(itertools.permutations(items, len(items)))\n",
    "            for lst in all_perms:\n",
    "                antecedent = lst[:len(lst) - 1]\n",
    "                consequent = lst[-1:]\n",
    "\n",
    "                conf = float(FreqItems[frozenset(items)]/FreqItems[frozenset(antecedent)]*100)\n",
    "                if (conf >= confidence):\n",
    "                    cnt += 1\n",
    "                    lift = float(conf/FreqItems[frozenset(consequent)])\n",
    "                    if lift >= 1:\n",
    "                        ant.append((antecedent))\n",
    "\n",
    "    print('Print %d attributes' % (cnt))\n",
    "    return ant\n",
    "\n",
    "def print_Frequent_Itemsets(output_FreqItems, FreqItems):\n",
    "    file = open(output_FreqItems, 'w+')\n",
    "    for item, support in FreqItems.items():\n",
    "        file.write(\" {} : {} \\n\".format(list(item), round(support,4)))\n",
    "\n",
    "def print_Rules(output_Rules, Rules):\n",
    "    file = open(output_Rules, 'w+')\n",
    "    for a, b,supp, conf, lift in sorted(Rules):\n",
    "        file.write(\"{} ==> {} support: {} confidence: {} \\n\".format((a), (b), round(supp, 4),round(conf, 4),round(lift, 4)))\n",
    "    file.close()\n",
    "    \n",
    "def print_Antecendent(ant):\n",
    "    file = open('output_antecendent.csv', 'w+')\n",
    "    for a in sorted(ant):\n",
    "        file.write(\"[] \\n\".format((a)))\n",
    "    file.close()\n",
    "    \n",
    "def Read_Data(filename, delimiter=','):\n",
    "    data = {}\n",
    "    trans = 0\n",
    "    f = open(filename, 'r', encoding=\"utf8\")\n",
    "    for row in f:\n",
    "        trans += 1\n",
    "        for item in row.split(delimiter):\n",
    "            if item not in data:\n",
    "                data[item] = set()\n",
    "            data[item].add(trans)\n",
    "    f.close()\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished reading data..... \n",
      " Starting mining .....\n",
      "found 56 Frequent items\n",
      "Found 0 Rules \n",
      "Writing Rules .....\n",
      "Print 0 attributes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7d466fbcd5f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint_Antecendent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAntecendent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mAnt1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAntecendent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAnt1d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    minsup   = 10\n",
    "    confidence = 75\n",
    "    output_FreqItems = 'output_freqitems.csv'\n",
    "    output_Rules = 'output_rule.csv'\n",
    "    dict_id = 0\n",
    "    data = Read_Data('retail.txt', ',') #change the delimiter based on your input file\n",
    "    data.pop(\"\\n\",None)\n",
    "    data.pop(\"\",None)\n",
    "    print('finished reading data..... \\n Starting mining .....')\n",
    "    eclat([], sorted(data.items(), key=lambda item: len(item[1]), reverse=True), dict_id)\n",
    "    print('found %d Frequent items' % len(FreqItems))\n",
    "    Rules = rules(FreqItems, confidence)\n",
    "    print('Writing Rules .....')\n",
    "\n",
    "\n",
    "\n",
    "    print_Frequent_Itemsets(output_FreqItems, FreqItems)\n",
    "    print_Rules(output_Rules, Rules)\n",
    "    Antecendent = getantecendent(FreqItems, confidence)\n",
    "    print_Antecendent(Antecendent)\n",
    "    \n",
    "    Ant1d = np.hstack(Antecendent)\n",
    "    \n",
    "    count = np.array(Ant1d)\n",
    "    unique, counts = np.unique(count, return_counts=True)\n",
    "    dict(zip(unique, counts))\n",
    "    counted = np.stack((unique, counts), axis=1)\n",
    "    appendFile = open('candidate.csv','w')\n",
    "    for i in range(0,len(counted)):\n",
    "        appendFile.write(str(unique[i])+\";\"+str(counts[i])+\",\"+\"\\n\")\n",
    "    appendFile.close()\n",
    "    \n",
    "    df = pd.DataFrame(counted, columns=['word','counter'])\n",
    "    df[\"counter\"] = pd.to_numeric(df[\"counter\"])\n",
    "    sortcounted = df.sort_values([\"counter\"], axis=0, \n",
    "                     ascending=[False]) \n",
    "    elimcounted = sortcounted.drop(sortcounted[sortcounted['counter']<2].index)\n",
    "    \n",
    "    listfrequent = list(elimcounted.iloc[:, 0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "(1,)\n",
      "(2,)\n",
      "(3,)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(2, 3)\n",
      "(1, 2, 3)\n",
      "[(), (1,), (2,), (3,), (1, 2), (1, 3), (2, 3), (1, 2, 3)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "for result in powerset([1, 2, 3]):\n",
    "    print(result)\n",
    "\n",
    "results = list(powerset([1, 2, 3]))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(abc, 2)\n",
      "(acdef, 1)\n",
      "(abc, 2)\n",
      "(de, 2)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "I = 'abcdef'\n",
    "T = ['abc', 'acdef', 'abc', 'de']\n",
    "\n",
    "\n",
    "for X in T:\n",
    "    cnt = sum([1 for i in T if set(X).issubset(set(i))])\n",
    "    if (cnt != 0):\n",
    "        print( \"(%s, %d)\" % (''.join(X), cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: for the set S={1,2,3,4,5} how many members will the power set have?\n",
    "Well, S has 5 members, so:\n",
    "\n",
    "|P(S)| = 2^n  = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frequency' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-680857b430db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0meclat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0meclat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-680857b430db>\u001b[0m in \u001b[0;36meclat\u001b[1;34m(prefix, items, D)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     candidates = [(prefix | {i}, frequency(D, prefix | {i}), i)\n\u001b[1;32m----> 8\u001b[1;33m                   for i in items if i not in prefix]\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mfrequent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-680857b430db>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     candidates = [(prefix | {i}, frequency(D, prefix | {i}), i)\n\u001b[1;32m----> 8\u001b[1;33m                   for i in items if i not in prefix]\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mfrequent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frequency' is not defined"
     ]
    }
   ],
   "source": [
    "th = 2\n",
    "i = 'abcdef'\n",
    "D = 3\n",
    "\n",
    "def eclat(prefix, items, D):\n",
    "    if not items: return\n",
    "    candidates = [(prefix | {i}, frequency(D, prefix | {i}), i)\n",
    "                  for i in items if i not in prefix]\n",
    "    frequent = filter(lambda x: x[1] >= th, candidates)\n",
    "\n",
    "    for new_prefix, freq, i in frequent:\n",
    "        frequent_items.append(new_prefix)\n",
    "        items = items - {i}\n",
    "        eclat(new_prefix, items, D)\n",
    "\n",
    "eclat(set(), set(I), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(['a','a','b']) | {'a'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [(set([1]),2,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({1}, 2, 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda i: i[1] >= 2, inp ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{abc,acdef,abc,de}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [{'a', 'd', 'e'},\n",
    "{'b', 'c', 'd'},\n",
    "{'a', 'c', 'e'},\n",
    "{'a', 'c', 'd', 'e'},\n",
    "{'a', 'e'},\n",
    "{'a', 'c', 'd'},\n",
    "{'b', 'c'},\n",
    "{'a', 'c', 'd', 'e'},\n",
    "{'b', 'c', 'e'},\n",
    "{'a', 'd', 'e'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(D, inp):\n",
    "    count = 0\n",
    "    for i in range(len(D)):\n",
    "        if inp.issubset(D[i]):\n",
    "            count += 1\n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Ii in frequent_items:\n",
    "    fi = {}\n",
    "    for Ij in frequent_items:\n",
    "        if Ii == frequent_items(k-1) - prefix & Ii > Ij:\n",
    "            Iij = Ii U Ij\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orderedset import OrderedSet\n",
    "\n",
    "th = 3\n",
    "counter = 0\n",
    "def eclat(prefix, items, D):\n",
    "    global counter\n",
    "    if not items: return\n",
    "    candidates = [(prefix | OrderedSet([i]), frequency(D, prefix | {i}), i)\n",
    "                  for i in items if i not in prefix]\n",
    "    frequent = candidates\n",
    "    frequent.sort(key = lambda x: x[2])\n",
    "    #frequent.sort(key = lambda x: x[1], reverse=True)\n",
    "    '''if  counter == 0:\n",
    "        items = [x[2] for x in frequent]\n",
    "        counter += 1\n",
    "    '''\n",
    "    frequent = list(filter(lambda x: x[1] >= th, candidates))\n",
    "    print(frequent)\n",
    "    for new_prefix, freq, i in frequent:\n",
    "        frequent_items.append(new_prefix)\n",
    "        try:\n",
    "            items.remove(i)\n",
    "        except:\n",
    "            pass\n",
    "        #print(items)\n",
    "        #print(new_prefix)\n",
    "        eclat(new_prefix, items, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(OrderedSet(['a']), 7, 'a'), (OrderedSet(['b']), 3, 'b'), (OrderedSet(['c']), 7, 'c'), (OrderedSet(['d']), 6, 'd'), (OrderedSet(['e']), 7, 'e')]\n",
      "[(OrderedSet(['a', 'c']), 4, 'c'), (OrderedSet(['a', 'd']), 5, 'd'), (OrderedSet(['a', 'e']), 6, 'e')]\n",
      "[(OrderedSet(['a', 'c', 'd']), 3, 'd'), (OrderedSet(['a', 'c', 'e']), 3, 'e')]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "eclat(OrderedSet(), ['a','b','c','d','e','f'], transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1,2,3,4,5}.intersection({1,2,3,4,5,6,7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedSet(['a']),\n",
       " OrderedSet(['a', 'c']),\n",
       " OrderedSet(['a', 'c', 'd']),\n",
       " OrderedSet(['a', 'c', 'e']),\n",
       " OrderedSet(['a', 'd']),\n",
       " OrderedSet(['a', 'e']),\n",
       " OrderedSet(['b']),\n",
       " OrderedSet(['c']),\n",
       " OrderedSet(['d']),\n",
       " OrderedSet(['e'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
